{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e660b241",
   "metadata": {
    "id": "e660b241"
   },
   "source": [
    "# MT5 Small Model\n",
    "\n",
    "In this notebook, we will be fine tuning the MT5 Sequence-to-Sequence Transformer model to take a Natural Language structured card specification to Java code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14974d65",
   "metadata": {
    "id": "14974d65"
   },
   "source": [
    "### Check for Cuda Compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "833e8cea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2799,
     "status": "ok",
     "timestamp": 1621206803279,
     "user": {
      "displayName": "Rachel Anderson",
      "photoUrl": "",
      "userId": "13786478264270865044"
     },
     "user_tz": 240
    },
    "id": "833e8cea",
    "outputId": "a2211b0d-3987-437f-e363-8fe984936671"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cxkouxtHOmFr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20045,
     "status": "ok",
     "timestamp": 1621206820529,
     "user": {
      "displayName": "Rachel Anderson",
      "photoUrl": "",
      "userId": "13786478264270865044"
     },
     "user_tz": 240
    },
    "id": "cxkouxtHOmFr",
    "outputId": "1003e46b-9489-41b8-8c48-e1b45f6d07bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "using_google_drive = True\n",
    "\n",
    "if using_google_drive:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    mahmoud_path = '/content/gdrive/MyDrive/Final Project/'\n",
    "    tommy_path = '/content/gdrive/MyDrive/Colab Notebooks/Final Project/'\n",
    "    path = mahmoud_path\n",
    "    PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4288262e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34191,
     "status": "ok",
     "timestamp": 1621206834677,
     "user": {
      "displayName": "Rachel Anderson",
      "photoUrl": "",
      "userId": "13786478264270865044"
     },
     "user_tz": 240
    },
    "id": "4288262e",
    "outputId": "d2debaea-01df-4e66-983b-517695dbcabf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacrebleu\n",
      "  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n",
      "Collecting portalocker==2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
      "Installing collected packages: portalocker, sacrebleu\n",
      "Successfully installed portalocker-2.0.0 sacrebleu-1.5.1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip -q install transformers\n",
    "pip -q install tqdm\n",
    "pip -q install sentencepiece \n",
    "pip -q install sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49a3c2f",
   "metadata": {
    "id": "a49a3c2f"
   },
   "source": [
    "# Tokenizer for the MT5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "614590d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256,
     "referenced_widgets": [
      "413ad385934f42268115e961d7728da2",
      "ef0b0b4803474d2784fdd6017b2ef421",
      "3594ba822dd640898ec2f677170afe15",
      "5f0b471fcbd7422fa7bc94bbaf7b2ddb",
      "1237e9141c5846fba3910bc31402285d",
      "41e21e9907be464296410216412620aa",
      "8666208bff064c28b623bc6512e06230",
      "3d42a401bdf147c2be663b4b59d06e29",
      "d84a1f28e9b2404594ed26585f53a3df",
      "8cf4fc972eb843cdbb92bf17453531c6",
      "abad7a9592064c5ca5c328468bea4583",
      "f73d0794f9254618b215574482772c64",
      "04cbdc813f4c4fdcbf67da2aba9ee5eb",
      "8f2f01c784f74013b33142c2b11918a4",
      "f9bc5a9678604a91b9cbbf2e888d053a",
      "d005e96f35c146cd987c3b69a6a53106",
      "76f95e794f09435f869704cb5d9697ac",
      "3e4f737197954bddb5ee5ca58f7ed5dd",
      "fdb6a30bd8ec4a8786cd4092d8d2e01f",
      "7aa2c8d0ea6242ad989f3089920bd299",
      "a6b74d4c35d7490d8c53c9c00ef43a36",
      "a5996bfbae844f7bb930fa602e02c389",
      "b2a9627682524572bd3bf2124c365312",
      "7c100193b5674bb5acd2c25e257295e5",
      "6e24bbe792d148eba76bb6344772709b",
      "88ac1a9f407049ec8cbb987658540096",
      "06bb79f05b4a41a9a6e381a89a5813a6",
      "1ec6cae9b8e24d74b4f6040f6081778b",
      "1a515159c181462ca4e4b6a89fec95cc",
      "ffb3459a18f8461f8e2e6de2c9c85b08",
      "c3efe49e6be34127b82ef4e0b44ea639",
      "00f1bc7dffd94bd2b860db9220b1eb5d"
     ]
    },
    "executionInfo": {
     "elapsed": 40714,
     "status": "ok",
     "timestamp": 1621206841204,
     "user": {
      "displayName": "Rachel Anderson",
      "photoUrl": "",
      "userId": "13786478264270865044"
     },
     "user_tz": 240
    },
    "id": "614590d1",
    "outputId": "e159504d-6907-4327-d95c-bb566743c2c3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413ad385934f42268115e961d7728da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=553.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84a1f28e9b2404594ed26585f53a3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=4309802.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f95e794f09435f869704cb5d9697ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=99.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e24bbe792d148eba76bb6344772709b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=82.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['▁', 'When', '▁this', '▁c', 'reature', '▁enter', 's', '▁the', '▁battle', '▁field', ',', '▁target', '▁c', 'reature', '▁los', 'es', '▁2', '▁life', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# Tokenizers\n",
    "import transformers\n",
    "#from transformers import MT5ForConditionalGeneration, T5Tokenizer\n",
    "pretrained_model_name = 'google/mt5-small'\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "context_ids = tokenizer.encode(\"When this creature enters the battle field, target creature loses 2 life.\")\n",
    "print(tokenizer.convert_ids_to_tokens(context_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58eb6160",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40714,
     "status": "ok",
     "timestamp": 1621206841205,
     "user": {
      "displayName": "Rachel Anderson",
      "photoUrl": "",
      "userId": "13786478264270865044"
     },
     "user_tz": 240
    },
    "id": "58eb6160",
    "outputId": "9531ecc4-6fc5-4ba3-edc4-85b7e0900d31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids\n",
      "tensor([[ 1662,   738, 36478, 23191,   455, 25972,   347,   461,   441,  4910,\n",
      "          6408,     1],\n",
      "        [25972,   347,   461,   441,  4910,  6408,     1,     0,     0,     0,\n",
      "             0,     0]])\n",
      "-------------------------\n",
      "attention_mask\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "ctx_list = [\n",
    "    \"You can protect yourself by wearing an N95 mask.\", \n",
    "    \"wearing an N95 mask\"\n",
    "]\n",
    "\n",
    "tokenizer_output = tokenizer.batch_encode_plus(\n",
    "    ctx_list,\n",
    "    max_length = 12,\n",
    "    truncation=True,\n",
    "    padding='longest',\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "for key, value in tokenizer_output.items():\n",
    "    print(key)\n",
    "    print(value)\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf8d9b7",
   "metadata": {
    "id": "bbf8d9b7"
   },
   "source": [
    "# Dataset Collection and Processing\n",
    "\n",
    "Load the dataset. The framework for making changes to individual points in the dataset is set in the `preprocess_datapoint` method, which at the moment does nothing to our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfd61e97",
   "metadata": {
    "executionInfo": {
     "elapsed": 44559,
     "status": "ok",
     "timestamp": 1621206845052,
     "user": {
      "displayName": "Rachel Anderson",
      "photoUrl": "",
      "userId": "13786478264270865044"
     },
     "user_tz": 240
    },
    "id": "bfd61e97"
   },
   "outputs": [],
   "source": [
    "with open(PATH + 'datasets/train_magic.in') as f:\n",
    "    train_x = f.readlines()\n",
    "with open(PATH + 'datasets/train_magic.out') as f:\n",
    "    train_y = f.readlines()\n",
    "with open(PATH + 'datasets/test_magic.in') as f:\n",
    "    test_x = f.readlines()\n",
    "with open(PATH + 'datasets/test_magic.out') as f:\n",
    "    test_y = f.readlines()\n",
    "# Structure the dataset somewhat similarly to the dataset objects\n",
    "training_dataset = [{ 'card': x, 'code': y } for x, y in zip(train_x, train_y)]\n",
    "testing_dataset  = [{ 'card': x, 'code': y } for x, y in zip(test_x,  test_y )]\n",
    "\n",
    "dataset = {\n",
    "    \"train\": training_dataset,\n",
    "    \"test\":  testing_dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1b8e1b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47556,
     "status": "ok",
     "timestamp": 1621206848051,
     "user": {
      "displayName": "Rachel Anderson",
      "photoUrl": "",
      "userId": "13786478264270865044"
     },
     "user_tz": 240
    },
    "id": "c1b8e1b5",
    "outputId": "fe7e005d-16a9-4441-a88a-5d57ce7f8ba6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11969/11969 [00:01<00:00, 9925.69it/s] \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "def preproc_init(tokenizer_for_model):\n",
    "    \"\"\" \n",
    "    Use this to assign global variables within a new thread \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tokenizer_for_mode: fn\n",
    "        The tokenizer for the pretrained transformer model\n",
    "    \"\"\"\n",
    "    global tokenizer\n",
    "    tokenizer = tokenizer_for_model\n",
    "\n",
    "def preprocess_datapoint (datapoint):\n",
    "    \"\"\"\n",
    "    Is effectively an identity function, but is here if we do preprocessing later\n",
    "    \n",
    "    This method will preprocess a single datapoint loaded above. This can involve\n",
    "    replacing characters, removing parts of the input or output, etc. The current\n",
    "    implementation applies no change to the dict. It can return None if we want to \n",
    "    remove this datapoint as well.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    datapoint: dict\n",
    "        The dict containing the initial value of each data in the dataset.\n",
    "        Each datapoint has the following two datapoints\n",
    "        \"card\": the string for the card description and meta data\n",
    "        \"code\": the string for the card implementation in Java\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A new representation for this individual datapoint.\n",
    "    \"\"\"\n",
    "    \n",
    "    # We have access to global vars defined in preproc_init\n",
    "    return datapoint\n",
    "    \n",
    "    \n",
    "def preprocess_dataset(dataset_list, threads, tokenizer):\n",
    "    \"\"\"\n",
    "    Preprocesses the entire dataset in `threads` threads\n",
    "    \n",
    "    This method opens `threads` new threads in\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_list: dict[]\n",
    "        A list of datapoints, where each datapoint is in the shape:\n",
    "        \"card\": the string for the card description and meta data\n",
    "        \"code\": the string for the card implementation in Java\n",
    "    threads: int\n",
    "        The number of threads to run the preprocessing on\n",
    "    tokenizer: fn\n",
    "        The tokenizer for the particular pretrained model\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A new representation for every datapoint in the dataset_list\n",
    "    \"\"\"\n",
    "    \n",
    "    # Open new threads and map tasks between them\n",
    "    with Pool(threads, initializer=preprocess_datapoint, initargs=(tokenizer,)) as p:\n",
    "        processed_dataset = list(tqdm(p.imap(preprocess_datapoint, dataset_list), total=len(dataset_list)))\n",
    "    # Remove None values in the list\n",
    "    processed_dataset = [x for x in processed_dataset if x]\n",
    "    \n",
    "    json.dump(processed_dataset, open(PATH + \"/processed_dataset.json\", 'w'))\n",
    "    return processed_dataset\n",
    "\n",
    "processed_dataset = preprocess_dataset(dataset['train'], 16, tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0f70c1",
   "metadata": {
    "id": "ed0f70c1"
   },
   "source": [
    "# Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a47d71c",
   "metadata": {
    "executionInfo": {
     "elapsed": 47555,
     "status": "ok",
     "timestamp": 1621206848052,
     "user": {
      "displayName": "Rachel Anderson",
      "photoUrl": "",
      "userId": "13786478264270865044"
     },
     "user_tz": 240
    },
    "id": "4a47d71c"
   },
   "outputs": [],
   "source": [
    "\n",
    "class ModelOutputs:\n",
    "    def __init__(self, output_logits=None, loss=None):\n",
    "        \"\"\"\n",
    "        An object containing the output of the CardTranslationModel\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        output_logits : torch.tensor\n",
    "            shape (batch_size, ans_len)\n",
    "        loss : torch.tensor\n",
    "            shape (1) The loss of the output\n",
    "\n",
    "        \"\"\"\n",
    "        self.output_logits = output_logits\n",
    "        self.loss = loss\n",
    "        \n",
    "class CardTranslationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, lm=None):\n",
    "        \"\"\"\n",
    "        Initializes the CardTranslationModel with the provided learning mdoel\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        lm : pretrained transformer\n",
    "            Description of arg1\n",
    "\n",
    "        \"\"\"\n",
    "        super(CardTranslationModel, self).__init__()\n",
    "        self.lm = lm\n",
    "    \n",
    "    def forward(self, input_ids=None, attention_mask=None, label_ids=None):\n",
    "        \"\"\"\n",
    "        Summary line.\n",
    "\n",
    "        Extended description of function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_ids : torch.tensor\n",
    "            shape (batch_size, seq_len) ids of the concatenated input tokens\n",
    "        attention_mask : torch.tensor\n",
    "            shape (batch_size, seq_len) concatenated attention masks\n",
    "        label_ids: torch.tensor\n",
    "            shape (batch_size, ans_len) the expected code output\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ModelOutputs\n",
    "            Description of return value\n",
    "\n",
    "        \"\"\"\n",
    "        # Feed our input ids into the pretrained transformer\n",
    "        lm_output = self.lm(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=label_ids,\n",
    "            use_cache=False\n",
    "        )\n",
    "        \n",
    "        # Compute Loss from the output of the learning model\n",
    "        total_loss = lm_output['loss']\n",
    "        if False and label_ids is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            total_loss = loss_fct(label_ids, lm_output['logits'])\n",
    "            \n",
    "        return ModelOutputs(\n",
    "            output_logits=lm_output['logits'],\n",
    "            loss=total_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af30dbc7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "f391aadd10fe4b69b7ae0699e3f6c7b8",
      "2a88e35e551c4b5ab95cf70ecafd67d2",
      "3973cf77fd5d44b3aa8363b791f88518",
      "c1455260a824448fa8723efd271ae851",
      "9043c669fda64309ad96a4bdca12412d",
      "70189aeb87f24893bed2ba8e8f76b918",
      "f91fa69ed836457092586384117528e4",
      "d36aae2af9b14bcfbb7f2d5c4201dc93"
     ]
    },
    "executionInfo": {
     "elapsed": 103118,
     "status": "ok",
     "timestamp": 1621206903617,
     "user": {
      "displayName": "Rachel Anderson",
      "photoUrl": "",
      "userId": "13786478264270865044"
     },
     "user_tz": 240
    },
    "id": "af30dbc7",
    "outputId": "085c791d-1fb2-44f8-85bd-eb38ff4bf5d7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f391aadd10fe4b69b7ae0699e3f6c7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1200794589.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import MT5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(pretrained_model_name)\n",
    "# Create the CardTranslationModel using the MT5 Conditional Generation model\n",
    "lm_pretrained = MT5ForConditionalGeneration.from_pretrained(pretrained_model_name)\n",
    "model = CardTranslationModel(lm_pretrained).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c019f2",
   "metadata": {
    "id": "58c019f2"
   },
   "source": [
    "## Up Next Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93b1c1fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 103120,
     "status": "ok",
     "timestamp": 1621206903620,
     "user": {
      "displayName": "Rachel Anderson",
      "photoUrl": "",
      "userId": "13786478264270865044"
     },
     "user_tz": 240
    },
    "id": "93b1c1fa",
    "outputId": "1c98492b-b2ec-4123-ab60-1b6c2e157289"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Training Info *****\n",
      "  Num examples = 29925\n",
      "  Num Epochs = 5\n",
      "  Batch size = 2\n",
      "  Total optimization steps = 29925\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Hyper-parameters: you could try playing with different settings\n",
    "num_epochs = 5\n",
    "learning_rate = 3e-5\n",
    "weight_decay = 1e-5\n",
    "eps = 1e-6\n",
    "batch_size = 2\n",
    "warmup_rate = 0.05\n",
    "card_max_length = 448\n",
    "code_max_length = 448\n",
    "\n",
    "# Calculating the number of warmup steps\n",
    "num_training_cases = len(processed_dataset)\n",
    "t_total = (num_training_cases // batch_size + 1) * num_epochs\n",
    "ext_warmup_steps = int(warmup_rate * t_total)\n",
    "\n",
    "# Initializing an AdamW optimizer\n",
    "ext_optim = torch.optim.AdamW(model.parameters(), lr=learning_rate,\n",
    "                              eps=eps, weight_decay=weight_decay)\n",
    "\n",
    "# Initializing the learning rate scheduler [details are in the BERT paper]\n",
    "# ext_sche = transformers.get_linear_schedule_with_warmup(\n",
    "#     ext_optim, num_warmup_steps=ext_warmup_steps, num_training_steps=t_total\n",
    "# )\n",
    "\n",
    "print(\"***** Training Info *****\")\n",
    "print(\"  Num examples = %d\" % t_total)\n",
    "print(\"  Num Epochs = %d\" % num_epochs)\n",
    "print(\"  Batch size = %d\" % batch_size)\n",
    "print(\"  Total optimization steps = %d\" % t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be52333c",
   "metadata": {
    "executionInfo": {
     "elapsed": 103119,
     "status": "ok",
     "timestamp": 1621206903622,
     "user": {
      "displayName": "Rachel Anderson",
      "photoUrl": "",
      "userId": "13786478264270865044"
     },
     "user_tz": 240
    },
    "id": "be52333c"
   },
   "outputs": [],
   "source": [
    "def vectorize_batch(batch, tokenizer):\n",
    "    \"\"\"\n",
    "    Converts the batch of processed datapoints into separate tensors of token ids\n",
    "    \n",
    "    Converts the batch of processed datapoints into separate tensors of token ids\n",
    "    hosted on the GPU. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    batch: str[]\n",
    "        shape (batch_size, 1)\n",
    "    tokenizer: fn\n",
    "        Converts the batch to a tensor of input and output ids\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    input_ids: torch.tensor\n",
    "        shape (batch_size, max_input_len)\n",
    "    input_attn_mask: torch.tensor\n",
    "        shape (batch_size, max_input_len)\n",
    "    label_ids: torch.tensor\n",
    "        shape (batch_size, max_output_len)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Separate the batch into input and output\n",
    "    card_batch = [card_data['card'] for card_data in batch]\n",
    "    code_batch = [code_data['code'] for code_data in batch]\n",
    "    \n",
    "    # Encode the card's natural language representation\n",
    "    card_encode = tokenizer.batch_encode_plus(\n",
    "        card_batch,\n",
    "        max_length = card_max_length,\n",
    "        truncation = True,\n",
    "        padding = 'longest',\n",
    "        return_attention_mask = True,\n",
    "        return_tensors = 'pt'\n",
    "    )\n",
    "\n",
    "    # Encode the card's java code representation\n",
    "    code_encode = tokenizer.batch_encode_plus(\n",
    "        code_batch,\n",
    "        max_length = code_max_length,\n",
    "        truncation = True,\n",
    "        padding = 'longest',\n",
    "        return_attention_mask = True,\n",
    "        return_tensors = 'pt'\n",
    "    )\n",
    "    \n",
    "    # Move the training batch to GPU\n",
    "    card_ids        = card_encode['input_ids'].cuda()\n",
    "    card_attn_mask  = card_encode['attention_mask'].cuda()\n",
    "    code_ids        = code_encode['input_ids'].cuda()\n",
    "    \n",
    "    return card_ids, card_attn_mask, code_ids\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "117272c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8851523,
     "status": "ok",
     "timestamp": 1621215652028,
     "user": {
      "displayName": "Rachel Anderson",
      "photoUrl": "",
      "userId": "13786478264270865044"
     },
     "user_tz": 240
    },
    "id": "117272c8",
    "outputId": "58c31ed5-f652-4d11-b197-de6513ce7cbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 0, the extraction loss = 27.42669105529785\n",
      "At step 100, the extraction loss = 23.36913299560547\n",
      "At step 200, the extraction loss = 20.11041831970215\n",
      "At step 300, the extraction loss = 11.491966247558594\n",
      "At step 400, the extraction loss = 10.240728378295898\n",
      "At step 500, the extraction loss = 7.24114465713501\n",
      "At step 600, the extraction loss = 4.9385986328125\n",
      "At step 700, the extraction loss = 3.3570027351379395\n",
      "At step 800, the extraction loss = 3.2423012256622314\n",
      "At step 900, the extraction loss = 2.9838950634002686\n",
      "At step 1000, the extraction loss = 3.0114777088165283\n",
      "At step 1100, the extraction loss = 2.369136095046997\n",
      "At step 1200, the extraction loss = 1.9337669610977173\n",
      "At step 1300, the extraction loss = 2.0089476108551025\n",
      "At step 1400, the extraction loss = 1.0087634325027466\n",
      "At step 1500, the extraction loss = 0.9787460565567017\n",
      "At step 1600, the extraction loss = 1.4310035705566406\n",
      "At step 1700, the extraction loss = 1.3666661977767944\n",
      "At step 1800, the extraction loss = 1.1607486009597778\n",
      "At step 1900, the extraction loss = 1.5134541988372803\n",
      "At step 2000, the extraction loss = 1.7148966789245605\n",
      "At step 2100, the extraction loss = 1.0815958976745605\n",
      "At step 2200, the extraction loss = 1.8246418237686157\n",
      "At step 2300, the extraction loss = 1.1198770999908447\n",
      "At step 2400, the extraction loss = 1.1242128610610962\n",
      "At step 2500, the extraction loss = 0.9191697835922241\n",
      "At step 2600, the extraction loss = 0.8780674338340759\n",
      "At step 2700, the extraction loss = 0.7124984264373779\n",
      "At step 2800, the extraction loss = 0.5556655526161194\n",
      "At step 2900, the extraction loss = 1.1693847179412842\n",
      "At step 3000, the extraction loss = 0.756405234336853\n",
      "At step 3100, the extraction loss = 0.9293815493583679\n",
      "At step 3200, the extraction loss = 0.7856726050376892\n",
      "At step 3300, the extraction loss = 1.0267770290374756\n",
      "At step 3400, the extraction loss = 1.2203233242034912\n",
      "At step 3500, the extraction loss = 0.7437225580215454\n",
      "At step 3600, the extraction loss = 0.9773829579353333\n",
      "At step 3700, the extraction loss = 1.0819579362869263\n",
      "At step 3800, the extraction loss = 1.0005775690078735\n",
      "At step 3900, the extraction loss = 0.4275340735912323\n",
      "At step 4000, the extraction loss = 0.6523104310035706\n",
      "At step 4100, the extraction loss = 0.8234095573425293\n",
      "At step 4200, the extraction loss = 0.6025868654251099\n",
      "At step 4300, the extraction loss = 1.2854207754135132\n",
      "At step 4400, the extraction loss = 0.4090226888656616\n",
      "At step 4500, the extraction loss = 0.6668330430984497\n",
      "At step 4600, the extraction loss = 0.7071539759635925\n",
      "At step 4700, the extraction loss = 0.6531234383583069\n",
      "At step 4800, the extraction loss = 0.9471729397773743\n",
      "At step 4900, the extraction loss = 0.5031733512878418\n",
      "At step 5000, the extraction loss = 1.4180824756622314\n",
      "At step 5100, the extraction loss = 0.7825360894203186\n",
      "At step 5200, the extraction loss = 0.6495810747146606\n",
      "At step 5300, the extraction loss = 0.5521975159645081\n",
      "At step 5400, the extraction loss = 0.3334417939186096\n",
      "At step 5500, the extraction loss = 0.6853172183036804\n",
      "At step 5600, the extraction loss = 0.34593647718429565\n",
      "At step 5700, the extraction loss = 0.8152886033058167\n",
      "At step 5800, the extraction loss = 0.21945123374462128\n",
      "At step 5900, the extraction loss = 0.7279553413391113\n",
      "At step 6000, the extraction loss = 0.5015457272529602\n",
      "At step 6100, the extraction loss = 0.752597987651825\n",
      "At step 6200, the extraction loss = 0.7410480380058289\n",
      "At step 6300, the extraction loss = 0.2949809432029724\n",
      "At step 6400, the extraction loss = 1.2870599031448364\n",
      "At step 6500, the extraction loss = 0.24797122180461884\n",
      "At step 6600, the extraction loss = 0.6508302092552185\n",
      "At step 6700, the extraction loss = 0.6074438095092773\n",
      "At step 6800, the extraction loss = 0.21315844357013702\n",
      "At step 6900, the extraction loss = 0.3965783715248108\n",
      "At step 7000, the extraction loss = 0.5654870867729187\n",
      "At step 7100, the extraction loss = 0.3093186616897583\n",
      "At step 7200, the extraction loss = 0.7512523531913757\n",
      "At step 7300, the extraction loss = 0.7772887349128723\n",
      "At step 7400, the extraction loss = 0.472146213054657\n",
      "At step 7500, the extraction loss = 0.20111046731472015\n",
      "At step 7600, the extraction loss = 0.40833866596221924\n",
      "At step 7700, the extraction loss = 0.6478528380393982\n",
      "At step 7800, the extraction loss = 0.33955439925193787\n",
      "At step 7900, the extraction loss = 0.4507996439933777\n",
      "At step 8000, the extraction loss = 0.4340634047985077\n",
      "At step 8100, the extraction loss = 0.2934355139732361\n",
      "At step 8200, the extraction loss = 0.16092024743556976\n",
      "At step 8300, the extraction loss = 0.3186894655227661\n",
      "At step 8400, the extraction loss = 0.5291315317153931\n",
      "At step 8500, the extraction loss = 0.7034416198730469\n",
      "At step 8600, the extraction loss = 0.6836539506912231\n",
      "At step 8700, the extraction loss = 0.5104719400405884\n",
      "At step 8800, the extraction loss = 0.5264183282852173\n",
      "At step 8900, the extraction loss = 0.512683629989624\n",
      "At step 9000, the extraction loss = 0.2742081582546234\n",
      "At step 9100, the extraction loss = 0.30157485604286194\n",
      "At step 9200, the extraction loss = 0.7200645804405212\n",
      "At step 9300, the extraction loss = 0.44359642267227173\n",
      "At step 9400, the extraction loss = 0.32372450828552246\n",
      "At step 9500, the extraction loss = 0.6433591246604919\n",
      "At step 9600, the extraction loss = 0.598628580570221\n",
      "At step 9700, the extraction loss = 0.5018230676651001\n",
      "At step 9800, the extraction loss = 0.5383405089378357\n",
      "At step 9900, the extraction loss = 0.5042721033096313\n",
      "At step 10000, the extraction loss = 0.5362268686294556\n",
      "At step 10100, the extraction loss = 0.6742969751358032\n",
      "At step 10200, the extraction loss = 0.21474777162075043\n",
      "At step 10300, the extraction loss = 0.5609588623046875\n",
      "At step 10400, the extraction loss = 0.3987993597984314\n",
      "At step 10500, the extraction loss = 0.1262146383523941\n",
      "At step 10600, the extraction loss = 0.7390260100364685\n",
      "At step 10700, the extraction loss = 0.21857938170433044\n",
      "At step 10800, the extraction loss = 0.38800469040870667\n",
      "At step 10900, the extraction loss = 0.23982185125350952\n",
      "At step 11000, the extraction loss = 0.42909422516822815\n",
      "At step 11100, the extraction loss = 0.6600440144538879\n",
      "At step 11200, the extraction loss = 0.504970133304596\n",
      "At step 11300, the extraction loss = 0.4201797544956207\n",
      "At step 11400, the extraction loss = 0.20326006412506104\n",
      "At step 11500, the extraction loss = 0.20859761536121368\n",
      "At step 11600, the extraction loss = 0.34249743819236755\n",
      "At step 11700, the extraction loss = 0.2430625706911087\n",
      "At step 11800, the extraction loss = 0.6703437566757202\n",
      "At step 11900, the extraction loss = 0.7071929574012756\n",
      "At step 12000, the extraction loss = 0.41943737864494324\n",
      "At step 12100, the extraction loss = 0.30614808201789856\n",
      "At step 12200, the extraction loss = 0.4945047199726105\n",
      "At step 12300, the extraction loss = 0.6519198417663574\n",
      "At step 12400, the extraction loss = 0.3450867235660553\n",
      "At step 12500, the extraction loss = 0.11693011224269867\n",
      "At step 12600, the extraction loss = 0.4378349781036377\n",
      "At step 12700, the extraction loss = 0.36536529660224915\n",
      "At step 12800, the extraction loss = 0.30169081687927246\n",
      "At step 12900, the extraction loss = 0.4471839964389801\n",
      "At step 13000, the extraction loss = 0.2306031733751297\n",
      "At step 13100, the extraction loss = 0.5430821180343628\n",
      "At step 13200, the extraction loss = 0.2801911532878876\n",
      "At step 13300, the extraction loss = 0.4989015758037567\n",
      "At step 13400, the extraction loss = 0.5380953550338745\n",
      "At step 13500, the extraction loss = 0.3418399393558502\n",
      "At step 13600, the extraction loss = 0.7957169413566589\n",
      "At step 13700, the extraction loss = 0.40531831979751587\n",
      "At step 13800, the extraction loss = 0.4823487401008606\n",
      "At step 13900, the extraction loss = 0.4548686146736145\n",
      "At step 14000, the extraction loss = 0.399920791387558\n",
      "At step 14100, the extraction loss = 0.1869756430387497\n",
      "At step 14200, the extraction loss = 0.5262470841407776\n",
      "At step 14300, the extraction loss = 0.3174189329147339\n",
      "At step 14400, the extraction loss = 0.3589947819709778\n",
      "At step 14500, the extraction loss = 0.1567850112915039\n",
      "At step 14600, the extraction loss = 0.3813924193382263\n",
      "At step 14700, the extraction loss = 0.1728142648935318\n",
      "At step 14800, the extraction loss = 0.5704279541969299\n",
      "At step 14900, the extraction loss = 0.3548668920993805\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "model.train()\n",
    "max_grad_norm = 1\n",
    "\n",
    "training_dataset = processed_dataset[:6000]\n",
    "num_training_cases = len(training_dataset)\n",
    "\n",
    "step_id = 0\n",
    "for _ in range(num_epochs):\n",
    "\n",
    "    random.shuffle(training_dataset)\n",
    "\n",
    "    for i in range(0, num_training_cases, batch_size):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        batch = training_dataset[i: i + batch_size]\n",
    "        input_ids, input_attn_mask, label_ids = vectorize_batch(batch, tokenizer)\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        model.zero_grad() # Does the same as ext_optim.zero_grad()\n",
    "\n",
    "        # Get the model outputs, including (start, end) logits and losses\n",
    "        # stored as a ModelOutput object\n",
    "        outputs = model(            \n",
    "            input_ids=input_ids,\n",
    "            attention_mask=input_attn_mask,\n",
    "            label_ids=label_ids\n",
    "        )\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Back-propagate the loss signal and clip the gradients\n",
    "        loss = outputs.loss.mean()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "        # Update neural network parameters and the learning rate\n",
    "        ext_optim.step()\n",
    "        # ext_sche.step() # Update learning rate for better convergence\n",
    "\n",
    "        if step_id % 100 == 0:\n",
    "            print(f'At step {step_id}, the extraction loss = {loss}')\n",
    "        \n",
    "        step_id += 1\n",
    "\n",
    "        input_ids.detach()\n",
    "        input_attn_mask.detach()\n",
    "        label_ids.detach()\n",
    "        outputs.loss.detach()\n",
    "        \n",
    "        del input_ids\n",
    "        del input_attn_mask\n",
    "        del label_ids\n",
    "        del outputs\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41543893",
   "metadata": {
    "executionInfo": {
     "elapsed": 8859258,
     "status": "ok",
     "timestamp": 1621215659764,
     "user": {
      "displayName": "Rachel Anderson",
      "photoUrl": "",
      "userId": "13786478264270865044"
     },
     "user_tz": 240
    },
    "id": "41543893"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/content/gdrive/MyDrive/MT5_checkpoint/MT5.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99fbf66a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8859259,
     "status": "ok",
     "timestamp": 1621215659766,
     "user": {
      "displayName": "Rachel Anderson",
      "photoUrl": "",
      "userId": "13786478264270865044"
     },
     "user_tz": 240
    },
    "id": "99fbf66a",
    "outputId": "f1a66810-ad1f-4a8d-d207-c0136d906269"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |    4586 MB |    9114 MB |  145854 GB |  145850 GB |\n",
      "|       from large pool |    4298 MB |    8755 MB |  134476 GB |  134472 GB |\n",
      "|       from small pool |     288 MB |     545 MB |   11377 GB |   11377 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |    4586 MB |    9114 MB |  145854 GB |  145850 GB |\n",
      "|       from large pool |    4298 MB |    8755 MB |  134476 GB |  134472 GB |\n",
      "|       from small pool |     288 MB |     545 MB |   11377 GB |   11377 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    5062 MB |    9412 MB |   49461 GB |   49456 GB |\n",
      "|       from large pool |    4666 MB |    8946 MB |   48081 GB |   48076 GB |\n",
      "|       from small pool |     396 MB |     614 MB |    1380 GB |    1379 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |  486854 KB |    1585 MB |   87248 GB |   87247 GB |\n",
      "|       from large pool |  376607 KB |    1471 MB |   74575 GB |   74575 GB |\n",
      "|       from small pool |  110247 KB |     118 MB |   12672 GB |   12672 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     761    |    1311    |   50847 K  |   50846 K  |\n",
      "|       from large pool |     200    |     580    |   17036 K  |   17036 K  |\n",
      "|       from small pool |     561    |    1025    |   33810 K  |   33810 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     761    |    1311    |   50847 K  |   50846 K  |\n",
      "|       from large pool |     200    |     580    |   17036 K  |   17036 K  |\n",
      "|       from small pool |     561    |    1025    |   33810 K  |   33810 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     221    |     339    |     955 K  |     955 K  |\n",
      "|       from large pool |      23    |      62    |     249 K  |     249 K  |\n",
      "|       from small pool |     198    |     307    |     706 K  |     706 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |     252    |     371    |   21213 K  |   21213 K  |\n",
      "|       from large pool |      19    |      26    |   10981 K  |   10981 K  |\n",
      "|       from small pool |     233    |     353    |   10231 K  |   10231 K  |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8113c214",
   "metadata": {
    "executionInfo": {
     "elapsed": 8859258,
     "status": "ok",
     "timestamp": 1621215659767,
     "user": {
      "displayName": "Rachel Anderson",
      "photoUrl": "",
      "userId": "13786478264270865044"
     },
     "user_tz": 240
    },
    "id": "8113c214"
   },
   "outputs": [],
   "source": [
    "\n",
    "#model.load_state_dict(torch.load(PATH + 'checkpoint.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64ee9f0e",
   "metadata": {
    "executionInfo": {
     "elapsed": 8859549,
     "status": "ok",
     "timestamp": 1621215660059,
     "user": {
      "displayName": "Rachel Anderson",
      "photoUrl": "",
      "userId": "13786478264270865044"
     },
     "user_tz": 240
    },
    "id": "64ee9f0e"
   },
   "outputs": [],
   "source": [
    "#---Sandbox code---#\n",
    "\n",
    "import random\n",
    "batch_size = 2\n",
    "i = random.randint(0, num_training_cases-1)\n",
    "\n",
    "datapoint = training_dataset[i:i + batch_size]\n",
    "#print(datapoint)\n",
    "card_ids, card_attn_masks, code_ids = vectorize_batch(datapoint, tokenizer)\n",
    "\n",
    "output = model(card_ids, card_attn_masks, code_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59e34677",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8864339,
     "status": "ok",
     "timestamp": 1621215664851,
     "user": {
      "displayName": "Rachel Anderson",
      "photoUrl": "",
      "userId": "13786478264270865044"
     },
     "user_tz": 240
    },
    "id": "59e34677",
    "outputId": "dd554740-f69b-4229-bf86-6c7d3768d7d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Card: Filigree Fracture NAME_END NIL ATK_END NIL DEF_END {2}{G} COST_END NIL DUR_END Instant TYPE_END Conflux PLAYER_CLS_END 82 RACE_END U RARITY_END Destroy target artifact or enchantment . If that permanent was blue or black , draw a card .\n",
      "\n",
      "Generated code:\n",
      "public class FiligreeCommute extends CardImpl {§public FiligreeCommute(UUID ownerId) {§super(ownerId, 82, \"Filgree Fracture\", Rarity.UNCOMMON, new CardType[]{CardType.INSTANT}, \"{2}{G}\");§this.expansionSetCode = \"CON\";§this.getSpellAbility().addEffect(new ConditionalTriggeredAbility(new DestroyTargetEffect());§this.getSpellAbility().addEffect(new DrawCardSourceControllerEffect(new FilterPermanent(\"artifact or enchantment\")), \"\"));§}§public FiligreeCommute(final FiligreeCommute card) {§super(card);§}§@Override§public FiligreeCommute copy() {§return new FiligreeCommute(this);§}§}§class FiligreeCommute(final FiligreeCommute card) {§super(card);§}§@Override§public FiligreeCommute copy() {§return new FiligreeCommute(this);§}§}§\n",
      "Ground-truth code: \n",
      "public class FiligreeFracture extends CardImpl {§public FiligreeFracture(UUID ownerId) {§super(ownerId, 82, \"Filigree Fracture\", Rarity.UNCOMMON, new CardType[]{CardType.INSTANT}, \"{2}{G}\");§this.expansionSetCode = \"CON\";§this.getSpellAbility().addTarget(new TargetPermanent(new FilterArtifactOrEnchantmentPermanent()));§this.getSpellAbility().addEffect(new DestroyTargetEffect());§this.getSpellAbility().addEffect(new FiligreeFractureEffect());§}§public FiligreeFracture(final FiligreeFracture card) {§super(card);§}§@Override§public FiligreeFracture copy() {§return new FiligreeFracture(this);§}§}§class FiligreeFractureEffect extends OneShotEffect {§public FiligreeFractureEffect() {§super(Outcome.DrawCard);§this.staticText = \"If that permanent was blue or black, draw a card\";§}§public FiligreeFractureEffect(final FiligreeFractureEffect effect) {§super(effect);§}§@Override§public FiligreeFractureEffect copy() {§return new FiligreeFractureEffect(this);§}§@Override§public boolean apply(Game game, Ability source) {§Player player = game.getPlayer(source.getControllerId());§Permanent permanent = (Permanent) game.getLastKnownInformation(source.getFirstTarget(), Zone.BATTLEFIELD);§if (player != null && permanent != null§&& (permanent.getColor(game).isBlack() || permanent.getColor(game).isBlue())) {§player.drawCards(1, game);§return true;§}§return false;§}§}§\n",
      "\n",
      "<class 'str'>\n",
      "732\n",
      "BLEU: 8.750712728100327\n"
     ]
    }
   ],
   "source": [
    "#---Sandbox code---#\n",
    "import sacrebleu\n",
    "\n",
    "\n",
    "#print(output.output_logits)\n",
    "softmax = torch.nn.Softmax(dim=1)(output.output_logits)\n",
    "\n",
    "input_id = tokenizer([datapoint[_]['card'] for _ in range(2)], padding=True, return_tensors='pt').input_ids.cuda()\n",
    "print('Card: ' + datapoint[0]['card'])\n",
    "#print(input_id)\n",
    "outputs = model.lm.generate(input_id, max_length=1000)\n",
    "#print(outputs.squeeze(0))\n",
    "#print(outputs[0])\n",
    "outputs = outputs[0][1:] # remove first pad\n",
    "#print(outputs)\n",
    "#print('wat:',(outputs == 0).nonzero(as_tuple=True))\n",
    "#print((outputs == 0).nonzero(as_tuple=True)[0][0])\n",
    "outputs = outputs[:int((outputs == 1).nonzero(as_tuple=True)[0][0])]\n",
    "code = tokenizer.decode(outputs)#[6:]\n",
    "print('Generated code:')\n",
    "print(code)\n",
    "#print(end)\n",
    "print('Ground-truth code: ')\n",
    "print(datapoint[0]['code'])\n",
    "print(type(datapoint[0]['code']))\n",
    "print(len(code))\n",
    "# how to sacrebleu: first arg is list of outputs, second arg is list of lists of allowable translations\n",
    "print('BLEU:', sacrebleu.raw_corpus_bleu([code], [[datapoint[0]['code']]]).score)\n",
    "#print(type(tokenizer))\n",
    "#print(type(code))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fafbd5f5",
   "metadata": {
    "executionInfo": {
     "elapsed": 8864339,
     "status": "ok",
     "timestamp": 1621215664853,
     "user": {
      "displayName": "Rachel Anderson",
      "photoUrl": "",
      "userId": "13786478264270865044"
     },
     "user_tz": 240
    },
    "id": "fafbd5f5"
   },
   "outputs": [],
   "source": [
    "def autoregressive_generate(model, tokenizer, card_desc):\n",
    "  '''\n",
    "  Applies autoregressive generation on a card description to generate its corresponding code\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  model: CardTranslationModel\n",
    "      Model used for autoregressive generation\n",
    "  tokenizer: transformers.models.tokenizer.PreTrainedTokenizer\n",
    "      Tokenizer for encoding the card description\n",
    "  card_desc: str or list[str] (batch_size length)\n",
    "      card description\n",
    "\n",
    "  Returns\n",
    "  ---------\n",
    "  torch.Tensor containing the sequence of code ids generated from the card description\n",
    "     shape: (batch_size, max_seq_len)\n",
    "'''\n",
    "  card_inputs = tokenizer(card_desc, padding=True, return_tensors='pt').input_ids.cuda()\n",
    "  return model.lm.generate(card_inputs)\n",
    "\n",
    "def decode(tokenizer, code_ids):\n",
    "  '''\n",
    "  Translates code ids into tokens\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  tokenizer: transformers.models.tokenizer.PreTrainedTokenizer\n",
    "      Tokenizer for decoding\n",
    "  code_ids: torch.Tensor\n",
    "      shape: (batch_size, max_seq_len)\n",
    "\n",
    "  Returns\n",
    "  ---------\n",
    "  list containing the token seq for each id sequence in the batch\n",
    "      shape (batch_size, max_seq_len)\n",
    "  '''\n",
    "  decode_output = tokenizer.batch_decode(code_ids)\n",
    "  return decode_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "095a050d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10689846,
     "status": "ok",
     "timestamp": 1621217490361,
     "user": {
      "displayName": "Rachel Anderson",
      "photoUrl": "",
      "userId": "13786478264270865044"
     },
     "user_tz": 240
    },
    "id": "095a050d",
    "outputId": "14f1ec17-d751-4aee-b938-220e84aa30e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huh Tibalt, the Fiend-Blooded NAME_END NIL ATK_END NIL DEF_END {R}{R} COST_END NIL DUR_END Planeswalker - Tibalt TYPE_END Avacyn Restored PLAYER_CLS_END 161 RACE_END M RARITY_END +1 : Draw a card , then discard a card at random . $-4 : Tibalt , the Fiend-Blooded deals damage equal to the number of cards in target player's hand to that player . $-6 : Gain control of all creatures until end of turn . Untap them . They gain haste until end of turn .\n",
      "\n",
      "BLEU: 34.91172539461733\n"
     ]
    }
   ],
   "source": [
    "test_data = testing_dataset[:200]\n",
    "bleu = 0\n",
    "for pt in test_data:\n",
    "  input_id = tokenizer([pt['card']], padding=True, return_tensors='pt').input_ids.cuda()\n",
    "  outputs = model.lm.generate(input_id, max_length=2000)\n",
    "  outputs = outputs[0][1:] # remove first pad\n",
    "  try:\n",
    "    outputs = outputs[:int((outputs == 1).nonzero(as_tuple=True)[0][0])] # truncate at end token\n",
    "  except:\n",
    "    print('huh', pt['card'])\n",
    "  code = tokenizer.decode(outputs)\n",
    "  #print('Generated code:')\n",
    "  #print(code) \n",
    "  #print('Ground-truth code: ')\n",
    "  #print(pt['code'])\n",
    "  bleu += sacrebleu.raw_corpus_bleu([code], [[pt['code']]]).score\n",
    "  #print('baby bleu:', bleu)\n",
    "print(\"BLEU:\", bleu/len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d22592cc",
   "metadata": {
    "executionInfo": {
     "elapsed": 10689847,
     "status": "ok",
     "timestamp": 1621217490364,
     "user": {
      "displayName": "Rachel Anderson",
      "photoUrl": "",
      "userId": "13786478264270865044"
     },
     "user_tz": 240
    },
    "id": "d22592cc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f359ba1a",
   "metadata": {
    "executionInfo": {
     "elapsed": 10689847,
     "status": "ok",
     "timestamp": 1621217490365,
     "user": {
      "displayName": "Rachel Anderson",
      "photoUrl": "",
      "userId": "13786478264270865044"
     },
     "user_tz": 240
    },
    "id": "f359ba1a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cc8400b",
   "metadata": {
    "executionInfo": {
     "elapsed": 10689845,
     "status": "ok",
     "timestamp": 1621217490365,
     "user": {
      "displayName": "Rachel Anderson",
      "photoUrl": "",
      "userId": "13786478264270865044"
     },
     "user_tz": 240
    },
    "id": "8cc8400b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MT5 Small Model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00f1bc7dffd94bd2b860db9220b1eb5d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04cbdc813f4c4fdcbf67da2aba9ee5eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "06bb79f05b4a41a9a6e381a89a5813a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ffb3459a18f8461f8e2e6de2c9c85b08",
      "max": 82,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1a515159c181462ca4e4b6a89fec95cc",
      "value": 82
     }
    },
    "1237e9141c5846fba3910bc31402285d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1a515159c181462ca4e4b6a89fec95cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1ec6cae9b8e24d74b4f6040f6081778b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00f1bc7dffd94bd2b860db9220b1eb5d",
      "placeholder": "​",
      "style": "IPY_MODEL_c3efe49e6be34127b82ef4e0b44ea639",
      "value": " 82.0/82.0 [00:00&lt;00:00, 163B/s]"
     }
    },
    "2a88e35e551c4b5ab95cf70ecafd67d2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3594ba822dd640898ec2f677170afe15": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41e21e9907be464296410216412620aa",
      "max": 553,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1237e9141c5846fba3910bc31402285d",
      "value": 553
     }
    },
    "3973cf77fd5d44b3aa8363b791f88518": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70189aeb87f24893bed2ba8e8f76b918",
      "max": 1200794589,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9043c669fda64309ad96a4bdca12412d",
      "value": 1200794589
     }
    },
    "3d42a401bdf147c2be663b4b59d06e29": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e4f737197954bddb5ee5ca58f7ed5dd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "413ad385934f42268115e961d7728da2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3594ba822dd640898ec2f677170afe15",
       "IPY_MODEL_5f0b471fcbd7422fa7bc94bbaf7b2ddb"
      ],
      "layout": "IPY_MODEL_ef0b0b4803474d2784fdd6017b2ef421"
     }
    },
    "41e21e9907be464296410216412620aa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f0b471fcbd7422fa7bc94bbaf7b2ddb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d42a401bdf147c2be663b4b59d06e29",
      "placeholder": "​",
      "style": "IPY_MODEL_8666208bff064c28b623bc6512e06230",
      "value": " 553/553 [00:00&lt;00:00, 1.22kB/s]"
     }
    },
    "6e24bbe792d148eba76bb6344772709b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_06bb79f05b4a41a9a6e381a89a5813a6",
       "IPY_MODEL_1ec6cae9b8e24d74b4f6040f6081778b"
      ],
      "layout": "IPY_MODEL_88ac1a9f407049ec8cbb987658540096"
     }
    },
    "70189aeb87f24893bed2ba8e8f76b918": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76f95e794f09435f869704cb5d9697ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fdb6a30bd8ec4a8786cd4092d8d2e01f",
       "IPY_MODEL_7aa2c8d0ea6242ad989f3089920bd299"
      ],
      "layout": "IPY_MODEL_3e4f737197954bddb5ee5ca58f7ed5dd"
     }
    },
    "7aa2c8d0ea6242ad989f3089920bd299": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c100193b5674bb5acd2c25e257295e5",
      "placeholder": "​",
      "style": "IPY_MODEL_b2a9627682524572bd3bf2124c365312",
      "value": " 99.0/99.0 [00:01&lt;00:00, 90.9B/s]"
     }
    },
    "7c100193b5674bb5acd2c25e257295e5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8666208bff064c28b623bc6512e06230": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88ac1a9f407049ec8cbb987658540096": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cf4fc972eb843cdbb92bf17453531c6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f2f01c784f74013b33142c2b11918a4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9043c669fda64309ad96a4bdca12412d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a5996bfbae844f7bb930fa602e02c389": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6b74d4c35d7490d8c53c9c00ef43a36": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "abad7a9592064c5ca5c328468bea4583": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f2f01c784f74013b33142c2b11918a4",
      "max": 4309802,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_04cbdc813f4c4fdcbf67da2aba9ee5eb",
      "value": 4309802
     }
    },
    "b2a9627682524572bd3bf2124c365312": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c1455260a824448fa8723efd271ae851": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d36aae2af9b14bcfbb7f2d5c4201dc93",
      "placeholder": "​",
      "style": "IPY_MODEL_f91fa69ed836457092586384117528e4",
      "value": " 1.20G/1.20G [00:43&lt;00:00, 27.9MB/s]"
     }
    },
    "c3efe49e6be34127b82ef4e0b44ea639": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d005e96f35c146cd987c3b69a6a53106": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d36aae2af9b14bcfbb7f2d5c4201dc93": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d84a1f28e9b2404594ed26585f53a3df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_abad7a9592064c5ca5c328468bea4583",
       "IPY_MODEL_f73d0794f9254618b215574482772c64"
      ],
      "layout": "IPY_MODEL_8cf4fc972eb843cdbb92bf17453531c6"
     }
    },
    "ef0b0b4803474d2784fdd6017b2ef421": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f391aadd10fe4b69b7ae0699e3f6c7b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3973cf77fd5d44b3aa8363b791f88518",
       "IPY_MODEL_c1455260a824448fa8723efd271ae851"
      ],
      "layout": "IPY_MODEL_2a88e35e551c4b5ab95cf70ecafd67d2"
     }
    },
    "f73d0794f9254618b215574482772c64": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d005e96f35c146cd987c3b69a6a53106",
      "placeholder": "​",
      "style": "IPY_MODEL_f9bc5a9678604a91b9cbbf2e888d053a",
      "value": " 4.31M/4.31M [00:02&lt;00:00, 1.51MB/s]"
     }
    },
    "f91fa69ed836457092586384117528e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f9bc5a9678604a91b9cbbf2e888d053a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fdb6a30bd8ec4a8786cd4092d8d2e01f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5996bfbae844f7bb930fa602e02c389",
      "max": 99,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a6b74d4c35d7490d8c53c9c00ef43a36",
      "value": 99
     }
    },
    "ffb3459a18f8461f8e2e6de2c9c85b08": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
